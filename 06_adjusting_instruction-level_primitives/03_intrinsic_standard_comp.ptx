//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33053471
// Cuda compilation tools, release 12.2, V12.2.128
// Based on NVVM 7.0.1
//

.version 8.2
.target sm_52
.address_size 64

	// .globl	_Z14standardKernelfPfi

.visible .entry _Z14standardKernelfPfi(
	.param .f32 _Z14standardKernelfPfi_param_0,
	.param .u64 _Z14standardKernelfPfi_param_1,
	.param .u32 _Z14standardKernelfPfi_param_2
)
{
	.reg .pred 	%p<25>;
	.reg .f32 	%f<95>;
	.reg .b32 	%r<41>;
	.reg .b64 	%rd<3>;


	ld.param.f32 	%f9, [_Z14standardKernelfPfi_param_0];
	ld.param.u64 	%rd1, [_Z14standardKernelfPfi_param_1];
	ld.param.u32 	%r18, [_Z14standardKernelfPfi_param_2];
	mov.u32 	%r19, %ntid.x;
	mov.u32 	%r20, %ctaid.x;
	mul.lo.s32 	%r21, %r20, %r19;
	mov.u32 	%r22, %tid.x;
	neg.s32 	%r23, %r22;
	setp.ne.s32 	%p2, %r21, %r23;
	@%p2 bra 	$L__BB0_25;

	setp.lt.s32 	%p3, %r18, 1;
	@%p3 bra 	$L__BB0_24;

	abs.f32 	%f1, %f9;
	setp.lt.f32 	%p4, %f1, 0f00800000;
	mul.f32 	%f11, %f1, 0f4B800000;
	selp.f32 	%f12, %f11, %f1, %p4;
	selp.f32 	%f13, 0fC1C00000, 0f00000000, %p4;
	mov.b32 	%r24, %f12;
	add.s32 	%r25, %r24, -1060439283;
	and.b32  	%r26, %r25, -8388608;
	sub.s32 	%r27, %r24, %r26;
	mov.b32 	%f14, %r27;
	cvt.rn.f32.s32 	%f15, %r26;
	mov.f32 	%f16, 0f34000000;
	fma.rn.f32 	%f17, %f15, %f16, %f13;
	add.f32 	%f18, %f14, 0fBF800000;
	add.f32 	%f19, %f14, 0f3F800000;
	mov.f32 	%f20, 0f3F800000;
	rcp.approx.ftz.f32 	%f21, %f19;
	add.f32 	%f22, %f18, %f18;
	mov.f32 	%f23, 0f40000000;
	mul.f32 	%f24, %f22, %f21;
	mul.f32 	%f25, %f24, %f24;
	sub.f32 	%f26, %f18, %f24;
	add.f32 	%f27, %f26, %f26;
	neg.f32 	%f28, %f24;
	fma.rn.f32 	%f29, %f28, %f18, %f27;
	mul.rn.f32 	%f30, %f21, %f29;
	mov.f32 	%f31, 0f3B52E7DB;
	mov.f32 	%f32, 0f3A2C32E4;
	fma.rn.f32 	%f33, %f32, %f25, %f31;
	mov.f32 	%f34, 0f3C93BB73;
	fma.rn.f32 	%f35, %f33, %f25, %f34;
	mov.f32 	%f36, 0f3DF6384F;
	fma.rn.f32 	%f37, %f35, %f25, %f36;
	mul.rn.f32 	%f38, %f37, %f25;
	mov.f32 	%f39, 0f3FB8AA3B;
	fma.rn.f32 	%f40, %f24, %f39, %f17;
	sub.f32 	%f41, %f17, %f40;
	fma.rn.f32 	%f42, %f24, %f39, %f41;
	fma.rn.f32 	%f43, %f30, %f39, %f42;
	mov.f32 	%f44, 0f32A55E34;
	fma.rn.f32 	%f45, %f24, %f44, %f43;
	mul.f32 	%f46, %f38, 0f40400000;
	fma.rn.f32 	%f47, %f46, %f30, %f45;
	fma.rn.f32 	%f48, %f38, %f24, %f47;
	add.rn.f32 	%f49, %f40, %f48;
	neg.f32 	%f50, %f40;
	add.rn.f32 	%f51, %f49, %f50;
	neg.f32 	%f52, %f51;
	add.rn.f32 	%f53, %f48, %f52;
	mul.rn.f32 	%f54, %f49, %f23;
	neg.f32 	%f55, %f54;
	fma.rn.f32 	%f56, %f49, %f23, %f55;
	fma.rn.f32 	%f57, %f53, %f23, %f56;
	cvt.rni.f32.f32 	%f58, %f54;
	sub.f32 	%f59, %f54, %f58;
	add.f32 	%f60, %f57, %f59;
	mov.f32 	%f61, 0f3AAF85ED;
	mov.f32 	%f62, 0f391FCB8E;
	fma.rn.f32 	%f63, %f62, %f60, %f61;
	mov.f32 	%f64, 0f3C1D9856;
	fma.rn.f32 	%f65, %f63, %f60, %f64;
	mov.f32 	%f66, 0f3D6357BB;
	fma.rn.f32 	%f67, %f65, %f60, %f66;
	mov.f32 	%f68, 0f3E75FDEC;
	fma.rn.f32 	%f69, %f67, %f60, %f68;
	mov.f32 	%f70, 0f3F317218;
	fma.rn.f32 	%f71, %f69, %f60, %f70;
	fma.rn.f32 	%f72, %f71, %f60, %f20;
	cvt.rzi.s32.f32 	%r28, %f58;
	setp.gt.f32 	%p5, %f58, 0f00000000;
	selp.b32 	%r29, 0, -2097152000, %p5;
	add.s32 	%r30, %r29, 2130706432;
	mov.b32 	%f73, %r30;
	mul.f32 	%f74, %f72, %f73;
	shl.b32 	%r31, %r28, 23;
	sub.s32 	%r32, %r31, %r29;
	mov.b32 	%f75, %r32;
	mul.f32 	%f76, %f74, %f75;
	abs.f32 	%f77, %f54;
	setp.gt.f32 	%p6, %f77, 0f43180000;
	setp.lt.f32 	%p7, %f54, 0f00000000;
	selp.f32 	%f78, 0f00000000, 0f7F800000, %p7;
	selp.f32 	%f94, %f78, %f76, %p6;
	add.s32 	%r1, %r18, -1;
	and.b32  	%r2, %r18, 3;
	setp.eq.f32 	%p8, %f9, 0f3F800000;
	@%p8 bra 	$L__BB0_21;
	bra.uni 	$L__BB0_3;

$L__BB0_21:
	setp.lt.u32 	%p23, %r1, 3;
	mov.f32 	%f94, %f20;
	@%p23 bra 	$L__BB0_24;

	sub.s32 	%r40, %r18, %r2;

$L__BB0_23:
	add.s32 	%r40, %r40, -4;
	setp.ne.s32 	%p24, %r40, 0;
	mov.f32 	%f94, %f20;
	@%p24 bra 	$L__BB0_23;
	bra.uni 	$L__BB0_24;

$L__BB0_3:
	setp.gtu.f32 	%p9, %f1, 0f7F800000;
	@%p9 bra 	$L__BB0_15;
	bra.uni 	$L__BB0_4;

$L__BB0_15:
	setp.lt.u32 	%p20, %r1, 3;
	@%p20 bra 	$L__BB0_19;

	sub.s32 	%r39, %r18, %r2;

$L__BB0_17:
	add.s32 	%r39, %r39, -4;
	setp.ne.s32 	%p21, %r39, 0;
	@%p21 bra 	$L__BB0_17;

	mov.f32 	%f88, 0f40000000;
	add.rn.f32 	%f94, %f9, %f88;

$L__BB0_19:
	setp.eq.s32 	%p22, %r2, 0;
	@%p22 bra 	$L__BB0_24;

	mov.f32 	%f89, 0f40000000;
	add.rn.f32 	%f94, %f9, %f89;
	bra.uni 	$L__BB0_24;

$L__BB0_4:
	mov.f32 	%f79, 0f3F800000;
	cvt.rzi.f32.f32 	%f80, %f79;
	add.f32 	%f81, %f80, %f80;
	mov.f32 	%f82, 0f40000000;
	sub.f32 	%f83, %f82, %f81;
	abs.f32 	%f84, %f83;
	setp.eq.f32 	%p1, %f84, 0f3F800000;
	setp.eq.f32 	%p10, %f1, 0f7F800000;
	setp.eq.f32 	%p11, %f9, 0f00000000;
	or.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_5;

$L__BB0_12:
	add.f32 	%f86, %f9, %f9;
	mov.b32 	%r33, %f86;
	and.b32  	%r34, %r33, 2147483647;
	selp.b32 	%r35, %r33, %r34, %p1;
	mov.b32 	%f94, %r35;
	setp.lt.u32 	%p18, %r1, 3;
	@%p18 bra 	$L__BB0_24;

	sub.s32 	%r38, %r18, %r2;

$L__BB0_14:
	add.s32 	%r38, %r38, -4;
	setp.eq.s32 	%p19, %r38, 0;
	@%p19 bra 	$L__BB0_24;
	bra.uni 	$L__BB0_14;

$L__BB0_5:
	setp.lt.f32 	%p13, %f9, 0f00000000;
	@%p13 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_6;

$L__BB0_9:
	neg.f32 	%f85, %f94;
	selp.f32 	%f94, %f85, %f94, %p1;
	setp.lt.u32 	%p16, %r1, 3;
	@%p16 bra 	$L__BB0_24;

	sub.s32 	%r37, %r18, %r2;

$L__BB0_11:
	add.s32 	%r37, %r37, -4;
	setp.eq.s32 	%p17, %r37, 0;
	@%p17 bra 	$L__BB0_24;
	bra.uni 	$L__BB0_11;

$L__BB0_6:
	setp.lt.u32 	%p14, %r1, 3;
	@%p14 bra 	$L__BB0_24;

	sub.s32 	%r36, %r18, %r2;

$L__BB0_8:
	add.s32 	%r36, %r36, -4;
	setp.eq.s32 	%p15, %r36, 0;
	@%p15 bra 	$L__BB0_24;
	bra.uni 	$L__BB0_8;

$L__BB0_24:
	cvta.to.global.u64 	%rd2, %rd1;
	st.global.f32 	[%rd2], %f94;

$L__BB0_25:
	ret;

}
	// .globl	_Z15intrinsicKernelfPfi
.visible .entry _Z15intrinsicKernelfPfi(
	.param .f32 _Z15intrinsicKernelfPfi_param_0,
	.param .u64 _Z15intrinsicKernelfPfi_param_1,
	.param .u32 _Z15intrinsicKernelfPfi_param_2
)
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<8>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<3>;


	ld.param.f32 	%f3, [_Z15intrinsicKernelfPfi_param_0];
	ld.param.u64 	%rd1, [_Z15intrinsicKernelfPfi_param_1];
	ld.param.u32 	%r1, [_Z15intrinsicKernelfPfi_param_2];
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mul.lo.s32 	%r4, %r3, %r2;
	mov.u32 	%r5, %tid.x;
	neg.s32 	%r6, %r5;
	setp.ne.s32 	%p1, %r4, %r6;
	@%p1 bra 	$L__BB1_4;

	setp.lt.s32 	%p2, %r1, 1;
	@%p2 bra 	$L__BB1_3;

	lg2.approx.f32 	%f5, %f3;
	add.f32 	%f6, %f5, %f5;
	ex2.approx.f32 	%f7, %f6;

$L__BB1_3:
	cvta.to.global.u64 	%rd2, %rd1;
	st.global.f32 	[%rd2], %f7;

$L__BB1_4:
	ret;

}

